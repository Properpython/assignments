{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1. What are the key tasks that machine learning entails? What does data pre-processing imply?"
      ],
      "metadata": {
        "id": "qFHFrRgswaDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Tasks in Machine Learning:\n",
        "\n",
        "Data Collection: Gathering relevant data from various sources, such as databases, APIs, or manual data entry.\n",
        "\n",
        "Data Pre-processing: Cleaning, transforming, and organizing the data to ensure it is suitable for the machine learning algorithms.\n",
        "\n",
        "Feature Engineering: Selecting, creating, or transforming features (variables) to provide meaningful information to the models.\n",
        "\n",
        "Model Selection: Choosing an appropriate machine learning model that matches the problem type (classification, regression, clustering, etc.) and data characteristics.\n",
        "\n",
        "Model Training: Feeding the prepared data into the chosen model to enable it to learn from the patterns and relationships in the data.\n",
        "\n",
        "Model Evaluation: Assessing the model's performance using evaluation metrics and validation techniques to ensure its accuracy and generalization ability.\n",
        "\n",
        "Hyperparameter Tuning: Fine-tuning the model's hyperparameters to optimize its performance.\n",
        "\n",
        "Model Deployment: Integrating the trained model into the production environment to make predictions on new, unseen data.\n",
        "\n",
        "Model Monitoring and Maintenance: Continuously monitoring the model's performance in the real-world scenario and updating it as needed.\n",
        "\n",
        "Data Pre-processing:\n",
        "Data pre-processing is a crucial step in machine learning that involves cleaning, transforming, and organizing the raw data to make it suitable for analysis and model training. It aims to improve the quality of the data, remove noise and inconsistencies, and handle missing values. Data pre-processing can include the following tasks:\n",
        "\n",
        "Data Cleaning: Identifying and handling missing data, duplicates, and outliers that can negatively impact model performance.\n",
        "\n",
        "Data Transformation: Normalizing or scaling the data to bring all features to a similar scale, preventing certain features from dominating others during model training.\n",
        "\n",
        "Feature Selection: Selecting the most relevant features that contribute significantly to the model's predictive power, reducing the dimensionality of the data.\n",
        "\n",
        "Encoding Categorical Variables: Converting categorical variables into numerical representations, as most machine learning algorithms require numerical input.\n",
        "\n",
        "Handling Imbalanced Data: Addressing class imbalance when the target variable has significantly more instances in one class than the others.\n",
        "\n",
        "Dealing with Text and Image Data: Pre-processing text data involves tokenization, stemming, and removing stop words, while image data may require resizing and normalization."
      ],
      "metadata": {
        "id": "C8Kc89sswZ9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Describe quantitative and qualitative data in depth. Make a distinction between the two."
      ],
      "metadata": {
        "id": "o27zr8zNwZ3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantitative Data:\n",
        "Quantitative data, also known as numerical data, consists of measurements or values that are represented using numbers. This type of data is continuous or discrete and can be subjected to mathematical operations. It provides information about quantities, amounts, or magnitudes. Examples of quantitative data include age, height, weight, temperature, income, and test scores.\n",
        "\n",
        "Qualitative Data:\n",
        "\n",
        "Qualitative data, also known as categorical data, consists of labels or categories used to describe characteristics or attributes of items. This type of data is non-numeric and cannot be subjected to arithmetic operations. Qualitative data provides information about qualities, attributes, or groupings. Examples of qualitative data include gender (male/female), color (red/blue/green), marital status (single/married/divorced), and education level (high school/bachelor's/master's)."
      ],
      "metadata": {
        "id": "i-kidENSwZxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Create a basic data collection that includes some sample records. Have at least one attribute from each of the machine learning data types."
      ],
      "metadata": {
        "id": "WPWLnlKbwZrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, here's a basic data collection with sample records that includes at least one attribute from each of the machine learning data types:\n",
        "\n",
        "ID\tName\tAge\tGender\tHeight (cm)\tWeight (kg)\tEducation Level\tIncome ($)\tMarital Status\n",
        "1\tJohn Smith\t28\tMale\t175\t70\tBachelor's\t50000\tSingle\n",
        "2\tJane Doe\t32\tFemale\t163\t55\tMaster's\t65000\tMarried\n",
        "3\tMichael Brown\t45\tMale\t182\t85\tHigh School\t40000\tDivorced\n",
        "4\tEmily White\t23\tFemale\t168\t58\tBachelor's\t42000\tSingle\n",
        "5\tRobert Johnson\t37\tMale\t190\t95\tDoctorate\t80000\tMarried\n",
        "Explanation of attributes:\n",
        "\n",
        "ID (Quantitative - Discrete): A unique identifier for each record.\n",
        "Name (Qualitative - Nominal): The name of the person, representing a category without an inherent order.\n",
        "Age (Quantitative - Continuous): The age of the person, representing a continuous numeric value.\n",
        "Gender (Qualitative - Nominal): The gender of the person, representing a category without an inherent order (Male or Female).\n",
        "Height (Quantitative - Continuous): The height of the person in centimeters, representing a continuous numeric value.\n",
        "Weight (Quantitative - Continuous): The weight of the person in kilograms, representing a continuous numeric value.\n",
        "Education Level (Qualitative - Ordinal): The educational attainment of the person, representing ordered categories from least to most advanced (e.g., High School, Bachelor's, Master's, Doctorate).\n",
        "Income (Quantitative - Continuous): The income of the person in dollars, representing a continuous numeric value.\n",
        "Marital Status (Qualitative - Nominal): The marital status of the person, representing a category without an inherent order (Single, Married, Divorced)."
      ],
      "metadata": {
        "id": "v-B59Y3JwZlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. What are the various causes of machine learning data issues? What are the ramifications?"
      ],
      "metadata": {
        "id": "pJGgtvwewZew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Various causes of machine learning data issues include:\n",
        "\n",
        "Incomplete Data: Missing values or incomplete records in the dataset can lead to biased or inaccurate models and may result in reduced model performance.\n",
        "\n",
        "Data Skewness: Imbalanced data, where one class significantly outweighs others, can lead to biased predictions and reduced accuracy for minority classes.\n",
        "\n",
        "Data Quality Issues: Data may contain errors, inconsistencies, or noise due to data entry mistakes, measurement errors, or other factors, affecting model performance.\n",
        "\n",
        "Outliers: Outliers are extreme values that deviate significantly from the rest of the data. They can distort statistical analysis and affect model accuracy if not handled appropriately.\n",
        "\n",
        "Feature Irrelevance: Including irrelevant or redundant features in the model can increase complexity, leading to overfitting or reduced interpretability.\n",
        "\n",
        "Data Leakage: When information from the target variable or future data is inadvertently included in the training data, it can result in inflated model performance and misleading predictions."
      ],
      "metadata": {
        "id": "AWYH1faAwZYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Demonstrate various approaches to categorical data exploration with appropriate examples."
      ],
      "metadata": {
        "id": "VKZY39qowZQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency Distribution:\n",
        "\n",
        "Display the counts or frequencies of each category in the dataset.\n",
        "\n",
        "Example:\n",
        "Let's say we have a dataset of students' grades in a class, and we want to explore the distribution of grades. The categories are 'A', 'B', 'C', 'D', and 'F'. We can create a frequency table like this:\n",
        "\n",
        "Grade\tCount\n",
        "A\t25\n",
        "B\t30\n",
        "C\t20\n",
        "D\t15\n",
        "F\t5\n",
        "Bar Chart:\n",
        "Visualize the frequencies of each category using a bar chart.\n",
        "\n",
        "Example:\n",
        "Continuing from the previous example, we can create a bar chart to visualize the grade distribution:\n",
        "\n",
        "Bar Chart\n",
        "\n",
        "Pie Chart:\n",
        "Display the proportion or percentage of each category using a pie chart.\n",
        "\n",
        "Example:\n",
        "We can create a pie chart to show the percentage of each grade category:\n",
        "\n",
        "Pie Chart\n",
        "\n",
        "Stacked Bar Chart:\n",
        "Compare the distribution of two categorical variables using a stacked bar chart.\n",
        "\n",
        "Example:\n",
        "Let's say we want to explore the distribution of grades in the class based on gender. We can create a stacked bar chart like this:\n",
        "\n"
      ],
      "metadata": {
        "id": "OVEB96ZYwZJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. How would the learning activity be affected if certain variables have missing values? Having said that, what can be done about it?"
      ],
      "metadata": {
        "id": "3MrMqZDtxylF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If certain variables have missing values, the learning activity can be significantly affected, as missing data can lead to biased, incomplete, or inaccurate models. Missing values can cause the following issues:\n",
        "\n",
        "Biased Results: If the missing data is not randomly distributed, it can introduce bias in the analysis and modeling, leading to incorrect conclusions.\n",
        "\n",
        "Reduced Sample Size: Missing values reduce the effective sample size, potentially reducing the statistical power of the analysis and the model's generalization ability.\n",
        "\n",
        "Incomplete Information: Missing values may result in incomplete information about relationships between variables, limiting the insights drawn from the data.\n",
        "\n",
        "Altered Data Distribution: If missing values are not handled properly, they can alter the distribution of the data and impact model performance."
      ],
      "metadata": {
        "id": "418h-L79xyhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Describe the various methods for dealing with missing data values in depth."
      ],
      "metadata": {
        "id": "3qqKgt_Vxyd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deletion Methods:\n",
        "\n",
        "Listwise Deletion (Complete Case Analysis): In this method, entire rows with missing values are removed from the dataset. It is straightforward to implement but may lead to a significant loss of data if missingness is not random. It is suitable when the missing data is assumed to be missing completely at random (MCAR).\n",
        "\n",
        "Pairwise Deletion (Available Case Analysis): In this approach, available data points are used for each calculation. It retains more data compared to listwise deletion, but different analyses may use different subsets of the data, leading to inconsistency in results.\n",
        "\n",
        "Advantages: Simple to implement, retains non-missing data integrity.\n",
        "\n",
        "Disadvantages: Reduces sample size, can introduce bias if missing data is not missing at random.\n",
        "\n",
        "Mean/Mode Imputation:\n",
        "\n",
        "Mean Imputation: For numeric variables, missing values are replaced with the mean of the available data for that variable. It is a straightforward method but may not be suitable if the data has a skewed distribution or outliers.\n",
        "\n",
        "Mode Imputation: For categorical variables, missing values are replaced with the mode (most frequent value) of the available data for that variable.\n",
        "\n",
        "Advantages: Easy to implement, does not distort the distribution of the variable.\n",
        "\n",
        "Disadvantages: Does not capture variability, can introduce bias if missing data is not missing at random."
      ],
      "metadata": {
        "id": "UK7aTVBLxyaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. What are the various data pre-processing techniques? Explain dimensionality reduction and function selection in a few words."
      ],
      "metadata": {
        "id": "c5d-EzcGyOnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning: Handling missing values, dealing with duplicates, and correcting errors in the dataset.\n",
        "\n",
        "Data Transformation: Scaling, normalization, and encoding categorical variables to bring data to a consistent format suitable for machine learning models.\n",
        "\n",
        "Feature Engineering: Creating new features or transforming existing ones to enhance the predictive power of the model.\n",
        "\n",
        "Feature Selection: Selecting the most relevant features from the dataset to reduce dimensionality and improve model efficiency.\n",
        "\n",
        "Dimensionality Reduction: Reducing the number of features while retaining the most important information to avoid the curse of dimensionality and improve model performance.\n",
        "\n",
        "Outlier Detection and Treatment: Identifying and handling outliers that can impact model training and prediction."
      ],
      "metadata": {
        "id": "TEZeLUwxyOhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9.\n",
        "\n",
        "i. What is the IQR? What criteria are used to assess it?\n",
        "\n",
        "ii. Describe the various components of a box plot in detail? When will the lower whisker"
      ],
      "metadata": {
        "id": "vzSfmNEnyObL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ". IQR (Interquartile Range): The IQR is a measure of statistical dispersion that quantifies the spread of data within the middle 50% of a dataset. It is the difference between the third quartile (Q3) and the first quartile (Q1) and is denoted as IQR = Q3 - Q1. The IQR is robust to outliers and provides a robust measure of variability in the data.\n",
        "\n",
        "Criteria to assess the IQR:\n",
        "\n",
        "It gives the range of the middle 50% of the data, making it less sensitive to extreme values or outliers.\n",
        "It can be used to identify potential outliers using the concept of the \"inner fences\" method, where data points outside the range Q1 - 1.5 * IQR to Q3 + 1.5 * IQR are considered outliers.\n",
        "ii. Components of a Box Plot:\n",
        "A box plot, also known as a box-and-whisker plot, is a graphical representation of the distribution of a dataset. It summarizes the five-number summary of the data: minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum.\n",
        "\n",
        "Minimum and Maximum: The minimum and maximum values of the data represent the smallest and largest observations in the dataset, respectively. These points are depicted as whiskers extending from the box."
      ],
      "metadata": {
        "id": "SnUC1V0tyOTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##10. Make brief notes on any two of the following:\n",
        "\n",
        "1. Data collected at regular intervals\n",
        "\n",
        "2. The gap between the quartiles\n",
        "\n",
        "3. Use a cross-tab"
      ],
      "metadata": {
        "id": "i9MJDOBzylnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Collected at Regular Intervals:\n",
        "\n",
        "Data collected at regular intervals, also known as time series data, is a type of data where observations are recorded at specific time points or intervals. This type of data is common in fields like finance, economics, weather forecasting, and more.\n",
        "Time series data is ordered and often shows patterns, trends, and seasonality over time. Analyzing time series data requires specialized techniques such as time series decomposition, autoregressive integrated moving average (ARIMA) modeling, or seasonal decomposition of time series (STL).\n",
        "Time series data can be plotted as line charts, where the x-axis represents time, and the y-axis represents the variable of interest. Understanding patterns and trends in time series data can help in making forecasts, identifying anomalies, and making data-driven decisions.\n",
        "\n",
        "The Gap Between the Quartiles:\n",
        "\n",
        "The gap between the quartiles refers to the difference between the third quartile (Q3) and the first quartile (Q1) in a dataset, i.e., the IQR (Interquartile Range) as mentioned in the previous question.\n",
        "\n",
        "The IQR is useful for detecting potential outliers. Data points below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR are considered outliers and may warrant further investigation. However, it is important to note that the IQR does not give information about the overall range of the data, as it only focuses on the middle 50%.\n",
        "A larger IQR indicates a wider spread of data within the middle 50%, while a smaller IQR indicates a more concentrated distribution.\n",
        "\n",
        "Use a Cross-Tab:\n",
        "\n",
        "A cross-tabulation, also known as a contingency table or crosstab, is a two-dimensional table that displays the frequency distribution of two or more categorical variables. It is a useful tool for exploring relationships and associations between categorical variables.\n",
        "Cross-tabs are commonly used to compare the distribution of one variable across the categories of another variable. This can help identify patterns and trends in the data and highlight any dependencies between the variables.\n",
        "Cross-tabs are easy to create using various data analysis tools like Excel, pandas (Python library), or other statistical software. They provide a simple way to summarize and visualize categorical data, making it easier to draw insights from the data."
      ],
      "metadata": {
        "id": "YOfDUM2SyvYM"
      }
    }
  ]
}